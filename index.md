# Portfolio
---
## Articles
---
[An In-depth Guide to OLS Assumptions: Connecting Procedural and Theory](https://medium.com/@christopher.daehyun.kim/an-in-depth-look-into-the-assumptions-of-ols-b7808ba72469)
\
\
In this article, I go over the assumptions of OLS that are commonly known. I wanted to provide an indepth examination on the what, where, why, and how of the assumptions with a focus on the linear algebra behind it all. I go over the procedural proofs of the assumptions, and how the assumptions all interconnect. 

---
## Projects 
---
### Audience Recommender System - Best Buy
\
This project was delivered at the finale of the practicum at Georgia Tech partnered with Best Buy. The focus was to contextualize customers and assign them to a specific number of audiences based on consumer behavior for a marketing campaign. It was a great exercise in terms of providing appropriate analytical solutions for a real company using real, anonymized data, feature engineering, and data wrangling/munging. This practicum project also provided experience working and collaborating with senior directors, managers, and data scientists at a high level. There was a meeting each week throughout the practicum with Best Buy representations, the TA, and other students in the group to discuss project scope, requirements, and other ideas. It was a really fun experience!
\
\
<img src = "images/penalize_1.png?raw=true"><br>
[Report](/pdfs/ChrisKim_AudienceRecommenderSystem_BestBuy_FinalPaper.pdf)<br>

---
### Interactive Visualization of Team Compositions Using Assocation Rules and Network Analysis in League of Legends
\
This project was delivered during my first semester at Georgia Tech for CSE6242: Data and Visual Analytics. I was the project manager and team leader of 5 other members. I was responsible for the vision, scope, and overall direction of the project. The focus was an end-to-end analytical solution comprising of creating an ELT/ETL pipeline of data sourced from the Riot Games API, data wrangling, coding machine learning algorithms by hand, and developing a visual tool in JavaScript to display the analytical results. Another priority when formulating the project was that the project itself was self contained. In other words, I wanted to make sure that the project was a reinforcement of the skills and objectives of the course content so that each member of the team can confidently contribute since the playing field was even. The course is a whirlwind of learning a wide range of tools and techniques, and I wanted to alleviate the cognitive load of the members by making sure that each step within the project scope could easily be referred to within the course.
\
<img src="images/euw_graph2.png?raw=true"/><br>
<img src="images/conf_graph1.png?raw=true"/><br>

[App for first graph](https://cdaekim.github.io/graph1)<br>

[App for second graph](https://cdaekim.github.io/graph2)<br>

[Poster](/pdfs/team139poster.pdf)<br>

[Report](/pdfs/team139report.pdf)<br>

---
### Assocation Rules as Sparsity Alleviation in Recommendation Systems
\
\
This project was also delivered during my first semester at Georgia Tech for the course ISYE6740: Computational Data Analysis. The focus was to augment the SVD algorithm that won the Netflix competition when Netflix was moving away from expert-user curated recommendations and to machine learning recommendations at scale. Since SVD inherently recreates the original matrix using factorized matrices, I wanted to include a step before the factorization process by using data mining techniques to impute missing values (i.e. user ratings). 
\
<img src = "images/asc_rules_img.PNG?raw=true"><br>
[Report](/pdfs/Kim_Christopher_project_report.pdf)<br>

